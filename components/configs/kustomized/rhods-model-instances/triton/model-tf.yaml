---
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "3"
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    openshift.io/display-name: GPT2 LLM - v1
    serving.kserve.io/deploymentMode: ModelMesh
  labels:
    name: triton-tf-gpt2
    opendatahub.io/dashboard: "true"
  name: triton-tf-gp2
spec:
  predictor:
    model:
      modelFormat:
        name: tensorflow
        version: "1"
      runtime: triton
      storage:
        key: s3-connection-minio
        path: gpt2/
